<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Predicting Power Outage Severity | power-outage-prediction</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Predicting Power Outage Severity" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="power-outage-prediction" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Predicting Power Outage Severity" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"Predicting Power Outage Severity","name":"power-outage-prediction","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="power-outage-prediction" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">power-outage-prediction</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/">Predicting Power Outage Severity</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><h1 class="page-heading">Predicting Power Outage Severity</h1><p>by Kate Feng and Tracy Vu</p>

<h1 id="introduction">Introduction</h1>

<p>This project explores how power outage data can be leveraged to predict the number of affected customers during an outage across different regions in the United States. In particular, we are investigating: <strong>How can we predict the number of affected customers based on factors like outage duration, region, and cause?</strong></p>

<p>The dataset we are using is Purdue University’s Major Power Outage Risks in the U.S. dataset, which consists of major power outages from January 2000 to July 2016 across the United States. Each of the 1,534 rows represents a single power outage occurrence, with 57 total columns containing information such as the duration of the outage, the state and region in which it occurred, and the category of the outage’s cause.</p>

<p>The columns we included in our analysis are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">'YEAR'</code> - This column labels the year that the power outage occurred.</li>
  <li><code class="language-plaintext highlighter-rouge">'MONTH'</code> - This column labels the month that the power outage occurred.</li>
  <li><code class="language-plaintext highlighter-rouge">'U.S._STATE'</code> - This column labels the state that the power outage was located. Column renamed to <code class="language-plaintext highlighter-rouge">'STATE'</code> for readability.</li>
  <li><code class="language-plaintext highlighter-rouge">'POSTAL.CODE'</code> - This column labels the abbreviation for the state the power outage was located. Column renamed to <code class="language-plaintext highlighter-rouge">'STATE.ABBV'</code> for readability.</li>
  <li><code class="language-plaintext highlighter-rouge">'CLIMATE.REGION'</code> - This column categorizes the region where the outage occurred. The possible values include:
    <ul>
      <li>East North Central (Northeast Midwest)</li>
      <li>Central</li>
      <li>Northeast</li>
      <li>Northwest</li>
      <li>South</li>
      <li>Southeast</li>
      <li>Southwest</li>
      <li>West</li>
      <li>West North Central</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">'CLIMATE.CATEGORY'</code> - This column categorizes the climate of the region where the outage occurred. The possible values include:
    <ul>
      <li>Normal</li>
      <li>Cold</li>
      <li>Warm</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code> - This column categorizes the overall cause of the outage. The possible values include:
    <ul>
      <li>Equipment failure</li>
      <li>Severe weather</li>
      <li>Public appeal</li>
      <li>Intentional attack</li>
      <li>Fuel supply emergency</li>
      <li>Islanding</li>
      <li>System operability</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY.DETAIL'</code> - This column gives some additional details to the categories causing the major power outage.</li>
  <li><code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> - This column represents the length of time (in minutes) that an outage persisted, providing a quantitative measure of outage severity.</li>
  <li><code class="language-plaintext highlighter-rouge">'CUSTOMERS.AFFECTED'</code> - This column represents the number of customers affected by the outage.</li>
  <li><code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> - This column represents the amount of energy (in megawatts) that the customers affected by the outage demanded during the duration of the outage. This column, as well as the <code class="language-plaintext highlighter-rouge">'CUSTOMERS.AFFECTED'</code> column, provide an examination into whether public pressure affects the speed of outage repair.</li>
  <li><code class="language-plaintext highlighter-rouge">'POPDEN_URBAN'</code> - This column represents the persons per square mile (population density) in the urban areas.</li>
  <li><code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>- This column represents the total megawatts of electricity consumed per hour in the respective state.</li>
  <li><code class="language-plaintext highlighter-rouge">'TOTAL.CUSTOMERS'</code> - This column represents the annual total number of customers served in the state the outage occurred in.</li>
  <li><code class="language-plaintext highlighter-rouge">'POPULATION'</code> - This column represents the yearly population of the state the outage occurred in.</li>
</ul>

<h1 id="data-cleaning-and-exploratory-data-analysis">Data Cleaning and Exploratory Data Analysis</h1>

<h2 id="data-cleaning">Data Cleaning</h2>
<p>In order to effectively analyze our dataset, we must first clean it. To do this, we first dropped columns that we knew we wouldn’t be using.
The dropped columns include: <code class="language-plaintext highlighter-rouge">"OBS"</code>, <code class="language-plaintext highlighter-rouge">"variables"</code>, <code class="language-plaintext highlighter-rouge">"RES.PRICE"</code>, <code class="language-plaintext highlighter-rouge">"COM.PRICE"</code>, <code class="language-plaintext highlighter-rouge">"IND.PRICE"</code>, <code class="language-plaintext highlighter-rouge">"TOTAL.PRICE"</code>, <code class="language-plaintext highlighter-rouge">"RES.SALES"</code>, <code class="language-plaintext highlighter-rouge">"COM.SALES"</code>, <code class="language-plaintext highlighter-rouge">"IND.SALES"</code>, <code class="language-plaintext highlighter-rouge">"RES.PERCEN"</code>, <code class="language-plaintext highlighter-rouge">"COM.PERCEN"</code>, <code class="language-plaintext highlighter-rouge">"IND.PERCEN"</code>, <code class="language-plaintext highlighter-rouge">"RES.CUSTOMERS"</code>, <code class="language-plaintext highlighter-rouge">"COM.CUSTOMERS"</code>, <code class="language-plaintext highlighter-rouge">"IND.CUSTOMERS"</code>, <code class="language-plaintext highlighter-rouge">"RES.CUST.PCT"</code>, <code class="language-plaintext highlighter-rouge">"COM.CUST.PCT"</code>, <code class="language-plaintext highlighter-rouge">"IND.CUST.PCT"</code>, <code class="language-plaintext highlighter-rouge">"PC.REALGSP.STATE"</code>, <code class="language-plaintext highlighter-rouge">"PC.REALGSP.USA"</code>, <code class="language-plaintext highlighter-rouge">"PC.REALGSP.REL"</code>, <code class="language-plaintext highlighter-rouge">"PC.REALGSP.CHANGE"</code>, <code class="language-plaintext highlighter-rouge">"UTIL.REALGSP"</code>, <code class="language-plaintext highlighter-rouge">"TOTAL.REALGSP"</code>, <code class="language-plaintext highlighter-rouge">"UTIL.CONTRI"</code>, <code class="language-plaintext highlighter-rouge">"PI.UTIL.OFUSA"</code>, <code class="language-plaintext highlighter-rouge">'POPPCT_URBAN'</code>, <code class="language-plaintext highlighter-rouge">'POPPCT_UC'</code>, <code class="language-plaintext highlighter-rouge">'POPDEN_UC'</code>, <code class="language-plaintext highlighter-rouge">'POPDEN_RURAL'</code>, <code class="language-plaintext highlighter-rouge">'AREAPCT_UC'</code>, <code class="language-plaintext highlighter-rouge">'PCT_LAND'</code>, <code class="language-plaintext highlighter-rouge">'PCT_WATER_TOT'</code>, <code class="language-plaintext highlighter-rouge">'PCT_WATER_INLAND'</code>, <code class="language-plaintext highlighter-rouge">'ANOMALY.LEVEL'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.START.DATE'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.START.TIME'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.RESTORATION.DATE'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.RESTORATION.TIME'</code>, <code class="language-plaintext highlighter-rouge">'HURRICANE.NAMES'</code>, <code class="language-plaintext highlighter-rouge">'NERC.REGION'</code>, <code class="language-plaintext highlighter-rouge">'AREAPCT_URBAN'</code>.</p>

<p>We converted the <code class="language-plaintext highlighter-rouge">'MONTH'</code> column from numerical values to text values and renamed columns (<code class="language-plaintext highlighter-rouge">'U.S._STATE'</code> to <code class="language-plaintext highlighter-rouge">'STATE'</code>, <code class="language-plaintext highlighter-rouge">'POSTAL.CODE'</code> to <code class="language-plaintext highlighter-rouge">'STATE.ABBV'</code>) for readability.</p>

<p>Furthermore, in order to predict the size of the customer base affected, we created another column called <code class="language-plaintext highlighter-rouge">'AFFECTED_BUCKET'</code> with labels based off of <code class="language-plaintext highlighter-rouge">'CUSTOMERS.AFFECTED'</code> with these bins:</p>

<table>
  <thead>
    <tr>
      <th><strong>Bin Range (Customers Affected)</strong></th>
      <th><strong>Label</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0 - 10,000</td>
      <td>Small Customer Base</td>
    </tr>
    <tr>
      <td>10,000 - 100,000</td>
      <td>Medium Customer Base</td>
    </tr>
    <tr>
      <td>100,000 - 500,000</td>
      <td>Large Customer Base</td>
    </tr>
    <tr>
      <td>500,000+</td>
      <td>Very Large Customer Base</td>
    </tr>
  </tbody>
</table>

<p>Below are a sample of rows from our cleaned dataset, with a portion of columns selected.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">STATE.ABBV</th>
      <th style="text-align: center">CLIMATE.CATEGORY</th>
      <th style="text-align: center">OUTAGE.DURATION</th>
      <th style="text-align: center">DEMAND.LOSS.MW</th>
      <th style="text-align: center">AFFECTED_BUCKET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">IN</td>
      <td style="text-align: center">cold</td>
      <td style="text-align: center">NaN</td>
      <td style="text-align: center">15</td>
      <td style="text-align: center">Large Customer Base</td>
    </tr>
    <tr>
      <td style="text-align: center">WI</td>
      <td style="text-align: center">cold</td>
      <td style="text-align: center">388</td>
      <td style="text-align: center">30</td>
      <td style="text-align: center">Small Customer Base</td>
    </tr>
    <tr>
      <td style="text-align: center">TX</td>
      <td style="text-align: center">warm</td>
      <td style="text-align: center">1320</td>
      <td style="text-align: center">NaN</td>
      <td style="text-align: center">Medium Customer Base</td>
    </tr>
    <tr>
      <td style="text-align: center">OR</td>
      <td style="text-align: center">normal</td>
      <td style="text-align: center">989</td>
      <td style="text-align: center">NaN</td>
      <td style="text-align: center">NaN</td>
    </tr>
    <tr>
      <td style="text-align: center">PA</td>
      <td style="text-align: center">normal</td>
      <td style="text-align: center">3189</td>
      <td style="text-align: center">NaN</td>
      <td style="text-align: center">Medium Customer Base</td>
    </tr>
  </tbody>
</table>

<h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2>

<h3 id="univariate-analysis">Univariate Analysis</h3>

<p><strong>Customer Base Size Histogram</strong></p>

<p>For our first univariate plot, we created a histogram to show the distribution of the customer base sizes. We found that most outages affected a <strong>medium to large customer base</strong>, with 371 outages affecting 10,000 to 100,000 customers and 385 outages affecting 100,000 to 500,000 customers.</p>
<iframe src="assets/affected_hist.html" width="800" height="420" frameborder="0"></iframe>

<p><strong>Chloropleth Map</strong></p>

<p>We also examined how the number of power outages varied by state. To visualize this, we created a choropleth map showing the distribution of power outages across different states. We grouped the data by <code class="language-plaintext highlighter-rouge">'STATE.ABBV'</code>, counted the number of rows per group, and added labels for the number of outages in states with over 50 outages. The major states here included <strong>California with 210 outages</strong>, <strong>Texas with 127 outages</strong>, and <strong>Washington with 97 outages</strong> over the 15.5 years of data.</p>
<iframe src="assets/outages_map.html" width="800" height="420" frameborder="0"></iframe>

<h3 id="bivariate-analysis">Bivariate Analysis</h3>
<h4 id="customer-base-vs-duration"><strong>Customer Base vs. Duration</strong></h4>
<p>We wanted to know if there was a relationship between the customer base categories <code class="language-plaintext highlighter-rouge">'AFFECTED_BUCKET'</code>, and the duration of power outages, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>. To explore this, we calculated the average outage duration for each customer base category and visualized it using a bar chart. Average outage duration grew as the customer base size increased, meaning that <strong>longer power outages affected greater groups of customers</strong>.</p>

<iframe src="assets/bar_region.html" width="800" height="420" frameborder="0"></iframe>

<p>The average outage duration across outages serving a “Very Large Customer Base” was close to 7,000 minutes compared to around 1,000 minutes for the “Small Customer Base”. This large difference is likely due to the <strong>North American Cold Wave in January-March 2014</strong> that caused power outages affecting large numbers of customers due to the frigid weather.</p>

<h4 id="electricity-consumption-over-time"><strong>Electricity Consumption Over Time</strong></h4>

<p>We also wanted to find out if there was a relationship between the <code class="language-plaintext highlighter-rouge">'YEAR'</code> and <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code> columns, to see if there was a correlation between the year and the average electricity consumption.</p>
<iframe src="assets/line_year.html" width="800" height="420" frameborder="0"></iframe>

<p>We found that there is a negative relationship between year and energy consumption, with the number of major outages peaking in 2001 before slowly decreasing.</p>

<h2 id="interesting-aggregates">Interesting Aggregates</h2>
<p>To further investigate the sales across climate regions, we created a pivot table. We grouped our first pivot table by the column, <code class="language-plaintext highlighter-rouge">CLIMATE.REGION</code>, and used the <code class="language-plaintext highlighter-rouge">mean()</code> function to determine the average <code class="language-plaintext highlighter-rouge">TOTAL.SALES</code> across the months. This allowed us to <strong>identify patterns in energy consumption based on climate regions over time.</strong></p>

<p>In general, the Southwest has less total energy consumption throughout the year. Below are a few months of the pivot table.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">MONTH</th>
      <th style="text-align: center">January</th>
      <th style="text-align: center">May</th>
      <th style="text-align: center">August</th>
      <th style="text-align: center">December</th>
    </tr>
    <tr>
      <th style="text-align: left"><strong>CLIMATE.REGION</strong></th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Central</td>
      <td style="text-align: center">9999134.88</td>
      <td style="text-align: center">8610485.55</td>
      <td style="text-align: center">12126452.0</td>
      <td style="text-align: center">9975352.22</td>
    </tr>
    <tr>
      <td style="text-align: left">East North Central</td>
      <td style="text-align: center">7115169.25</td>
      <td style="text-align: center">7823724.9</td>
      <td style="text-align: center">8709003.54</td>
      <td style="text-align: center">8894578.7</td>
    </tr>
    <tr>
      <td style="text-align: left">Northeast</td>
      <td style="text-align: center">6633505.48</td>
      <td style="text-align: center">5711189.12</td>
      <td style="text-align: center">9024923.71</td>
      <td style="text-align: center">7670454.57</td>
    </tr>
    <tr>
      <td style="text-align: left">Southwest</td>
      <td style="text-align: center">3759643.0</td>
      <td style="text-align: center">3276493.33</td>
      <td style="text-align: center">4101329.0</td>
      <td style="text-align: center">4280192.57</td>
    </tr>
    <tr>
      <td style="text-align: left">West</td>
      <td style="text-align: center">18323967.46</td>
      <td style="text-align: center">19400558.89</td>
      <td style="text-align: center">25358698.5</td>
      <td style="text-align: center">20674018.24</td>
    </tr>
    <tr>
      <td style="text-align: left">West North Central</td>
      <td style="text-align: center">NaN</td>
      <td style="text-align: center">1433063.0</td>
      <td style="text-align: center">1563340.75</td>
      <td style="text-align: center">1798136.0</td>
    </tr>
  </tbody>
</table>

<p>Similar to the pivot table above, we also wanted to investigate energy consumption patterns across different temperatures, <code class="language-plaintext highlighter-rouge">CLIMATE.CATEGORY</code>, for each state. We applied the mean() aggregate function to <code class="language-plaintext highlighter-rouge">TOTAL.SALES</code>. Below are the first few rows of the table.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">CLIMATE.CATEGORY</th>
      <th style="text-align: center">cold</th>
      <th style="text-align: center">normal</th>
      <th style="text-align: center">warm</th>
    </tr>
    <tr>
      <th style="text-align: left"><strong>STATE</strong></th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Alabama</td>
      <td style="text-align: center">7647656.0</td>
      <td style="text-align: center">7193314.5</td>
      <td style="text-align: center">8934377.0</td>
    </tr>
    <tr>
      <td style="text-align: left">Arizona</td>
      <td style="text-align: center">5425664.57</td>
      <td style="text-align: center">6438748.0</td>
      <td style="text-align: center">5547223.57</td>
    </tr>
    <tr>
      <td style="text-align: left">Arkansas</td>
      <td style="text-align: center">3880604.86</td>
      <td style="text-align: center">4163933.6</td>
      <td style="text-align: center">3706199.33</td>
    </tr>
    <tr>
      <td style="text-align: left">California</td>
      <td style="text-align: center">21693834.79</td>
      <td style="text-align: center">22031934.17</td>
      <td style="text-align: center">21332614.62</td>
    </tr>
    <tr>
      <td style="text-align: left">Colorado</td>
      <td style="text-align: center">4030931.67</td>
      <td style="text-align: center">4421043.75</td>
      <td style="text-align: center">4289402.0</td>
    </tr>
  </tbody>
</table>

<h1 id="assessment-of-missingness">Assessment of Missingness</h1>
<h2 id="nmar-analysis">NMAR Analysis</h2>

<p>The column <code class="language-plaintext highlighter-rouge">'CUSTOMERS.AFFECTED'</code> is likely NMAR because its missingness does not depend on other columns. Instead, the missingness of this column depends on how each company records the number of customers affected, as <strong>this column aggregates data from multiple companies.</strong> Variations in reporting standards, such as differing thresholds for what constitutes an affected customer or inconsistencies in data collection methods, could lead to systematic patterns of missingness.</p>

<p>However, if we had access to each company’s recording standards, the missingness might be MAR rather than NMAR.</p>

<h2 id="missingness-dependency">Missingness Dependency</h2>
<p>There are various columns where there is missing data. We wanted to find out if the total electricity consumption, <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>, is dependent on the missingness in the electricity demand loss column, <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code>.</p>

<iframe src="assets/sales_missing.html" width="800" height="420" frameborder="0"></iframe>

<p>Our set of hypotheses were:</p>

<p><strong>Null Hypothesis:</strong> The missingness of the data in the <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> column does not depend on the total electricity consumption, <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>.</p>

<p><strong>Alternative Hypothesis:</strong> The missingness of the data in the <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> column does depend on the total electricity consumption, <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>.</p>

<p>Our test statistic was the difference in means between average <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code> for data without missing <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> and the average <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code> for data with missing <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code>. We got a low p-value of 0.001, which is below the standard 0.05 significance threshold. We obtained a low p-value of 0.001, which is below the standard 0.05 significance threshold.</p>

<p>Therefore, we <strong>reject the null hypothesis</strong> and conclude that the missingness of <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> is dependent on <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>: when <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code> is lower, <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> is more likely to be missing.</p>

<p>This dependency is possibly due to reporting bias, where locations with less electricity consumption do not have record of the demand loss because it is seen as less impactful.</p>

<iframe src="assets/dependent_hist.html" width="800" height="420" frameborder="0"></iframe>

<p>Next, we wanted to see if the missingness of the electricity demand loss column, <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code>, depended on the duration of the power outage, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>.</p>

<p>Our set of hypotheses for this test were:</p>

<p><strong>Null Hypothesis:</strong> The missingness of the data in the <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> column does not depend on the length of the power outage, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>.</p>

<p><strong>Alternative Hypothesis:</strong> The missingness of the data in the <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> column does depend on the length of the power outage, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>.</p>

<iframe src="assets/duration_missing.html" width="800" height="420" frameborder="0"></iframe>

<p>We performed a permutation test by shuffling the “Missing/Not Missing” labels for the <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code> column, and calculated the difference in average outage durations between both groups.</p>

<p>Our observed difference in duration was 128.76 minutes and our p-value for this permutation test was 0.34. Using a significance level of 5%, we determine that this is a high p-value and therefore <strong>fail to reject the null.</strong> The difference in mean durations between missing and non-missing demand loss data was likely due to chance.</p>

<iframe src="assets/duration_missing_hist.html" width="800" height="420" frameborder="0"></iframe>

<h1 id="hypothesis-testing">Hypothesis Testing</h1>
<p>We conducted a test to investigate whether there is a significant difference in the average <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> between the ‘Very Large Customer Base’ group and the other groups in the <code class="language-plaintext highlighter-rouge">'AFFECTED_BUCKET'</code> column.</p>

<p>Recall from the first univariate plot that the average outage duration, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>, was the <strong>highest in the ‘Very Large Customer Base’ group.</strong> We aim to test if this significant difference is statistically significant or due to random chance.</p>

<p><strong>Null Hypothesis:</strong> The mean <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> in the ‘Very Large Customer Base’ group is not longer than the mean <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> in other groups.</p>

<p><strong>Alternative Hypothesis:</strong> The mean <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> in the ‘Very Large Customer Base’ group is longer than the mean <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> in other groups.</p>

<p><strong>Test Statistic</strong>: The difference between the observed mean of the ‘Very Large Customer Base’ group and the mean from the permutation distribution.</p>

<iframe src="assets/hypothesis_test.html" width="800" height="420" frameborder="0"></iframe>

<p>The p-value came out to be extremely small (essentially 0.0), meaning we can <strong>reject the null hypothesis at a 0.01 significance level.</strong> This provides strong evidence that outages affecting ‘Very Large Customer Base’ group, on average, are longer compared to outages affecting other groups.</p>

<h1 id="framing-a-prediction-problem">Framing a Prediction Problem</h1>

<p>Our model will aim to <strong>predict the number of customers affected by a power outage</strong>. We binned our <code class="language-plaintext highlighter-rouge">'CUSTOMERS.AFFECTED'</code> column, with the buckets being Small Customer Base (0 - 10,000), Medium Customer Base (10,000 - 100,000), Large Customer Base (100,000 - 500,000), and Very Large Customer Base (500,000+).</p>

<p>This will be a <strong>multiclass classification</strong> model since there are various buckets that an outage could fall into. We chose to predict this variable because we believe that it would be useful in future efforts of preparation and prioritization regarding power outages.</p>

<p>The metric used will be an <strong>F1-score</strong> since there are multiple classes, meaning that there may be class imbalances, which is why it is better than using accuracy as a metric. We wanted to ensure that our model had both high precision (avoid false positives) and high recall (avoid false negatives).</p>

<p>At the time of prediction, we would know the <strong>outage duration, climate region, cause category, climate category, urban population density, total customers of the state</strong> (annually), <strong>population of the state, total sales of the state</strong> (total electricity consumption), and <strong>demand loss</strong> (peak demand lost during the outage). This provides us with information to predict the size of the customer base that was affected.</p>

<h1 id="baseline-model">Baseline Model</h1>

<p>For our baseline model, we are using a Random Forest Classifier with these four features: <code class="language-plaintext highlighter-rouge">'CLIMATE.REGION'</code>, <code class="language-plaintext highlighter-rouge">'CLIMATE.CATEGORY'</code>, <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>. The first three variables, <code class="language-plaintext highlighter-rouge">'CLIMATE.REGION'</code>, <code class="language-plaintext highlighter-rouge">'CLIMATE.CATEGORY'</code>, <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code>, contain nominal values while the last variable, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>, contains continuous quantitative values of minutes.</p>

<p>These features were chosen since we believed they helped utility companies understand which outages are likely to have a larger impact, based on our previous analyses.</p>

<p>A higher duration value could represent higher severity in an outage. Cause category reveals the outage cause and climate category reveals the climate type, both of which may impact duration and severity. Climate region shows the geographic region, which provides information for severity and customers affected. 
These features provide key insights for affected customers.</p>

<p>We one hot encoded the nominal variables, <code class="language-plaintext highlighter-rouge">'CLIMATE.REGION'</code>, <code class="language-plaintext highlighter-rouge">'CLIMATE.CATEGORY'</code>, <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code> to ensure that they were properly interpreted by the classifier. We passed <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> through as-is because applying transformations like Standard Scaler would not improve the accuracy since the Random Forest model splits data based on thresholds in each feature.</p>

<p>The metric, F1 score, of this model is 0.55. The F1 score for each customer base bucket is shown below:</p>

<table>
  <thead>
    <tr>
      <th>Class</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-Score</th>
      <th>Support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Large Customer Base</td>
      <td>0.48</td>
      <td>0.53</td>
      <td>0.50</td>
      <td>73</td>
    </tr>
    <tr>
      <td>Medium Customer Base</td>
      <td>0.42</td>
      <td>0.45</td>
      <td>0.43</td>
      <td>67</td>
    </tr>
    <tr>
      <td>Small Customer Base</td>
      <td>0.92</td>
      <td>0.85</td>
      <td>0.89</td>
      <td>55</td>
    </tr>
    <tr>
      <td>Very Large Customer Base</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>16</td>
    </tr>
    <tr>
      <td><strong>Accuracy</strong></td>
      <td> </td>
      <td> </td>
      <td><strong>0.55</strong></td>
      <td><strong>211</strong></td>
    </tr>
    <tr>
      <td><strong>Macro avg</strong></td>
      <td>0.45</td>
      <td>0.46</td>
      <td>0.46</td>
      <td>211</td>
    </tr>
    <tr>
      <td><strong>Weighted avg</strong></td>
      <td>0.54</td>
      <td>0.55</td>
      <td>0.54</td>
      <td>211</td>
    </tr>
  </tbody>
</table>

<p>This model best predicts ‘Small Customer Base’, likely because there are clear patterns (such as shorter outage duration or easily-fixed outage cause) to predict an outage affecting less people.</p>

<p>The accuracy for the ‘Very Large Customer Base’ was 0, meaning this model was not able to predict outages affecting over 500,000 customers at all. This is likely due to the small number of examples in the dataset for this category, with 16 examples. This model ended up having a mediocre F1-score, so there is a lot of room for improvement.</p>

<h1 id="final-model">Final Model</h1>

<p>Since our accuracy for the last model was low, we wanted to analyze <strong>which features we should continue using for our final model</strong> and which features were decreasing the accuracy.</p>

<iframe src="assets/first_importance.html" width="800" height="420" frameborder="0"></iframe>

<p>Upon plotting the feature importances, we found that the variables <code class="language-plaintext highlighter-rouge">'CLIMATE.REGION'</code> and <code class="language-plaintext highlighter-rouge">'CLIMATE.CATEGORY'</code> contributed very little to predicting customer base size. In contrast, certain values in <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code>, such as ‘severe weather’ and ‘intentional attack’, had higher importance. Notably, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code> had the highest importance, indicating that the model relied heavily on this feature when making splits.</p>

<p>For the final model, we <strong>removed the two non-contributing features and added five more new features,</strong> bringing the total to seven features: <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code>, <code class="language-plaintext highlighter-rouge">'POPDEN_URBAN'</code>, <code class="language-plaintext highlighter-rouge">'TOTAL.CUSTOMERS'</code>, <code class="language-plaintext highlighter-rouge">'OUTAGE.DURATION'</code>, <code class="language-plaintext highlighter-rouge">'POPULATION'</code>, <code class="language-plaintext highlighter-rouge">'TOTAL.SALES'</code>, and <code class="language-plaintext highlighter-rouge">'DEMAND.LOSS.MW'</code>.</p>

<p>The additional features included:</p>
<ul>
  <li><strong>Population</strong> (discrete), representing the size of the area impacted by the outage.</li>
  <li><strong>Total Sales</strong> (continuous), reflecting the energy consumption in a region and helping to express the severity of the outage.</li>
  <li><strong>Total Customers</strong> (discrete), indicating the number of customers in the affected state, which can give a better sense of the potential impact.</li>
  <li><strong>Demand Loss</strong> (continuous), which relates to the economic impact of the outage, highlighting its severity.</li>
  <li><strong>Urban Population Density</strong> (discrete), which provides insight into how densely populated an area is, and potentially how many people would be affected by the outage.</li>
</ul>

<p>We included these additional features because they seemed to represent critical factors affecting the impact of outages on customers. Features like population and urban density help to capture the size of the affected area, while total sales and demand loss give a better gauge of the outage’s economic and energy impact. Together, these factors enhance our model’s ability to predict the severity of outages on customers.</p>

<p>We used GridSearchCV to find the optimized hyperparameters for the Random Forest Classifier:</p>
<ul>
  <li>max_features: ‘sqrt’</li>
  <li>min_samples_leaf: 2</li>
  <li>min_samples_split’: 5</li>
  <li>n_estimators’: 300</li>
</ul>

<p>However, when we looked at the classification report, we found that the F1-scores across the report <strong>were lower compared to the default parameters</strong>:</p>

<table>
  <thead>
    <tr>
      <th>Class</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-Score</th>
      <th>Support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Large Customer Base</td>
      <td>0.53</td>
      <td>0.75</td>
      <td>0.62</td>
      <td>32</td>
    </tr>
    <tr>
      <td>Medium Customer Base</td>
      <td>0.74</td>
      <td>0.60</td>
      <td>0.67</td>
      <td>48</td>
    </tr>
    <tr>
      <td>Small Customer Base</td>
      <td>0.98</td>
      <td>0.96</td>
      <td>0.97</td>
      <td>52</td>
    </tr>
    <tr>
      <td>Very Large Customer Base</td>
      <td>0.67</td>
      <td>0.33</td>
      <td>0.44</td>
      <td>6</td>
    </tr>
    <tr>
      <td><strong>Accuracy</strong></td>
      <td> </td>
      <td> </td>
      <td><strong>0.76</strong></td>
      <td><strong>138</strong></td>
    </tr>
    <tr>
      <td><strong>Macro avg</strong></td>
      <td>0.73</td>
      <td>0.66</td>
      <td>0.68</td>
      <td>138</td>
    </tr>
    <tr>
      <td><strong>Weighted avg</strong></td>
      <td>0.78</td>
      <td>0.76</td>
      <td>0.76</td>
      <td>138</td>
    </tr>
  </tbody>
</table>

<p>We can compare these scores to the scores using these default parameters:</p>
<ul>
  <li>max_features: ‘auto’ (model will consider all features)</li>
  <li>min_samples_leaf: 1</li>
  <li>min_samples_split: 2</li>
  <li>n_estimators: 100</li>
</ul>

<p>In the default parameters, the F1 score of this improved model is 0.80. The F1 score for each customer base bucket is shown below:</p>

<table>
  <thead>
    <tr>
      <th>Class</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-Score</th>
      <th>Support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Large Customer Base</td>
      <td>0.60</td>
      <td>0.75</td>
      <td>0.67</td>
      <td>32</td>
    </tr>
    <tr>
      <td>Medium Customer Base</td>
      <td>0.77</td>
      <td>0.62</td>
      <td>0.69</td>
      <td>48</td>
    </tr>
    <tr>
      <td>Small Customer Base</td>
      <td>0.96</td>
      <td>0.98</td>
      <td>0.97</td>
      <td>52</td>
    </tr>
    <tr>
      <td>Very Large Customer Base</td>
      <td>0.83</td>
      <td>0.83</td>
      <td>0.83</td>
      <td>6</td>
    </tr>
    <tr>
      <td><strong>Accuracy</strong></td>
      <td> </td>
      <td> </td>
      <td><strong>0.80</strong></td>
      <td><strong>138</strong></td>
    </tr>
    <tr>
      <td><strong>Macro avg</strong></td>
      <td>0.79</td>
      <td>0.80</td>
      <td>0.79</td>
      <td>138</td>
    </tr>
    <tr>
      <td><strong>Weighted avg</strong></td>
      <td>0.81</td>
      <td>0.80</td>
      <td>0.80</td>
      <td>138</td>
    </tr>
  </tbody>
</table>

<p>The decreased accuracy in the hyperparameter tuning is likely due to overfitting of the training data or class imbalance (the model becomes more sensitive to majority classes). Therefore, we will use the default parameters instead of the hyperparameters found with GridSearchCV.</p>

<p>The <strong>overall F1-Score improved to 0.80</strong>, reflecting an increase in accuracy across all customer base categories. Notably, the ‘Very Large Customer Base’ saw a significant improvement, with its <strong>F1-Score rising from 0.0 to 0.83</strong>. Despite the sample size being small (only 6 samples), the model performed much better due to the inclusion of more features, which allowed the ‘Very Large Customer Base’ to be more adequately represented.</p>

<p>Additionally, the accuracy for other categories also showed improvement. For example, the ‘Small Customer Base’ now has an <strong>impressive F1-Score of 0.97</strong>, demonstrating that the model can effectively predict this category.</p>

<p>These improvements suggest that with more features and better representation, the model has become more capable of distinguishing between the various customer base categories.</p>

<p>We can visualize the prediction accuracy in a confusion matrix:</p>
<iframe src="assets/confusion_matrix.html" width="800" height="420" frameborder="0"></iframe>

<h1 id="fairness-analysis">Fairness Analysis</h1>

<p>Our groups to test the model’s fairness are whether the cause of the outage, <code class="language-plaintext highlighter-rouge">'CAUSE.CATEGORY'</code>, was <strong>system operability disruption</strong> or not. We used the accuracy as the evaluation metric since it represents the proportion of correct predictions made for both groups. This metric suits the classification problem as we are trying to see whether the model is accurate in distinguishing between severe weather and other outage causes.</p>

<p>We decided to test the model’s fairness on these groups because we found that the <strong>false negative rates of outages caused by system operability disruption were the highest out of all the cause categories.</strong> This raised our concerns about whether the model was underperforming for this cause.</p>

<iframe src="assets/fnr_cause.html" width="800" height="420" frameborder="0"></iframe>

<p><strong>Null Hypothesis:</strong> The model is fair. Its accuracy for system operability disruption and non-system operability disruption cases are roughly the same, and any differences are due to random chance.</p>

<p><strong>Alternative Hypothesis:</strong> The model is unfair. Its accuracy for system operability disruption and non-system operability disruption cases are significantly different.</p>

<p><strong>Test Statistic:</strong> The difference in accuracy between “system operability disruption” and the rest of the categories.</p>

<p>We conducted a permutation test with 5,000 trials to assess whether the accuracy of our model differs when predicting power outages caused by “system operability disruption” compared to all other causes. Our observed accuracy difference was -0.21, and we obtained a p-value of 0.079. Since this p-value exceeds the standard significance threshold of 0.05, we <strong>fail to reject the null hypothesis.</strong></p>

<p>These results suggest that the observed lower accuracy for system operability disruption is not statistically significant and <strong>may be due to random variation rather than a true effect.</strong> While there appears to be an association between system operability disruption and reduced accuracy, the evidence is insufficient to conclude that this difference is meaningful.</p>

<iframe src="assets/fairness_perm.html" width="800" height="420" frameborder="0"></iframe>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">power-outage-prediction</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">power-outage-prediction</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
